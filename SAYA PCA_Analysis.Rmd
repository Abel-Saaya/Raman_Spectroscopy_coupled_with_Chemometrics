```{r}
# Load necessary libraries
library(signal) 
library(pls)

# Load the data (reflectance data without converting to absorbance)
spectra <- read.csv("Concentration.csv", sep=",", dec=".", header=TRUE)
```

```{r}
str(spectra)
head(spectra)

```

```{r}
# Check the structure of spectra
str(spectra)

# Print the column names
print(colnames(spectra))

# Ensure correct access to the Wavenumber column
if ("Wavenumber..cm.1." %in% colnames(spectra)) {
    # Create the data frame
    mydata <- data.frame(label = spectra$Wavenumber..cm.1., DRS = spectra[, -1])  # Exclude first column for DRS
    
    # Check if the number of rows matches
    if (nrow(mydata) > 0) {
        print("Data frame created successfully.")
    } else {
        stop("The data frame is empty.")
    }
} else {
    stop("Column 'Wavenumber..cm.1.' does not exist in the spectra data frame.")
}

```



```{r}
# Create a data frame for wavelengths and reflectance data
mydata <- data.frame(label = spectra$`Wavenumber (cm-1)`, DRS = spectra[, -1])

# Retrieve wavelength numbers
wavelengths <- mydata$label

# Sort the data by decreasing wavelength
mydata <- mydata[order(mydata$label, decreasing = TRUE),]
```

```{r}
colnames(spectra)

```

```{r}
# Ensure correct access to the Wavenumber column
if ("Wavenumber..cm.1." %in% colnames(spectra)) {
    # Create the data frame
    mydata <- data.frame(label = spectra$Wavenumber..cm.1., DRS = spectra[, -1])  # Exclude first column for DRS
    
    # Check if the number of rows matches
    if (nrow(mydata) > 0) {
        print("Data frame created successfully.")
    } else {
        stop("The data frame is empty.")
    }
} else {
    stop("Column 'Wavenumber..cm.1.' does not exist in the spectra data frame.")
}

```
```{r}
nrow(spectra)  # Total number of rows in the spectra data frame
nrow(spectra$Wavenumber..cm.1.)  # Rows in the wavenumber column
nrow(spectra[, -1])  # Rows in the remaining columns

```

```{r}
label_column <- as.vector(spectra$Wavenumber..cm.1.)
DRS_columns <- as.data.frame(spectra[, -1])  # Convert remaining columns to a data frame

mydata <- data.frame(label = label_column, DRS = DRS_columns)

```

```{r}
# Create a data frame for wavelengths and reflectance data
#mydata <- data.frame(label = spectra$`Wavenumber (cm-1)`, DRS = spectra[, -1])

# Retrieve wavelength numbers
wavelengths <- mydata$label

# Sort the data by decreasing wavelength
mydata <- mydata[order(mydata$label, decreasing = TRUE),]
```

```{r}
# Define your custom plotting function
mercy_plot <- function(mydata, wavelengths, xlim, ylim, main, ylab, x, y) {
  unique_labels <- unique(gsub("[^A-Za-z]+", "", colnames(mydata$DRS)))
  num_labels <- length(unique_labels)
  color_palette <- rainbow(num_labels)
  names(color_palette) <- unique_labels
  
  plot(NULL, xlim = xlim, ylim = ylim, xlab = "Wavelength (nm)", ylab = ylab, main = main)
  
  for (i in 1:ncol(mydata$DRS)) {
    matlines(wavelengths, mydata$DRS[, i], col = color_palette[i], lty = 1, lwd = 2)
  }
  
  minor.tick(nx = 2, ny = 2, tick.ratio = 0.75)
}
```

```{r}
# Apply Savitzky-Golay smoothing for first and second derivatives
apply_sgolay <- function(spectra, p, n, m) 
  apply(spectra, 1, FUN = sgolayfilt, p = p, n = n, m = m, ts = 1)
```

```{r}
# SNV function
SNV <- function(spectra) {
  spectra <- as.matrix(spectra)
  spectrat <- t(spectra)
  spectrat_snv <- scale(spectrat, center = TRUE, scale = TRUE)
  spectra_snv <- t(spectrat_snv)
  return(spectra_snv)
}
```

```{r}
# Normalize spectra function
normalize_spectra <- function(spectra) {
  spectra <- as.matrix(spectra)
  min_val <- apply(spectra, 1, min)
  max_val <- apply(spectra, 1, max)
  normalized_spectra <- (spectra - min_val) / (max_val - min_val)
  return(normalized_spectra)
}
```

```{r}
# Apply Savitzky-Golay smoothing, SNV, and derivatives
mydataSmoothSG <- apply_sgolay(mydata$DRS, p = 2, n = 5, m = 0)  # Savitzky-Golay smoothing
mydataFirstDerivative <- apply_sgolay(mydata$DRS, p = 2, n = 5, m = 1)  # First derivative
mydataSecondDerivative <- apply_sgolay(mydata$DRS, p = 2, n = 5, m = 2)  # Second derivative

```



---
title: "Analysis"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


```{r}
rm ( list = ls ()) 
library (squash) 
library (Hmisc) 
library(pavo)
par (mfrow= c (1,1))
```

#Create a plot function:
```{r}
mercy_plot<-function (mydata, wavelengths, xlim, ylim,main,ylab){ 
#Create color map: 
map <- makecmap( as.numeric (mydata $ label),n = 2, breaks = pretty ,
symm = FALSE, base = NA,
colFn = colorRampPalette( c("red","green","blue")), col.na = NA, 
right = FALSE, include.lowest = FALSE) 
mycol <- cmap(mydata $ label, map = map)
par (font=2,las=1,mar = c (5,4,4,10) + 0.1)
#Plot spectra: 
matplot (wavelengths, t (mydata $ DRS),font.axis =2, col =mycol,lty=1, xlab="",ylab="",type="l",lwd=3, xlim=xlim, ylim=ylim,main=main)
minor.tick(nx=2, ny=2,tick.ratio=0.75) 
par (mar = c (5,4,4,6) + 0.1) 
title (xlab="Wavelength ␣ (nm)",ylab=ylab,font.lab=2) 
#Plot color map: 
vkey(map, title = "Key",stretch=2.4, side=2, skip=2, x=1100,y= min (ylim)) 
}
```


```{r}
#Define plot limits: 
xlim <-c (500,1600)
ylim <-c (50,1000) 
main <- "" 
ylab <- ""
```

## Some EDA ON the RAW Spectra
#setwd(" ˜/ data ") 
## we need to normalise the data to get rid of the negative � → reflectance 
#values before converting to apparent absorbance. #Flatten or squash a list of lists into a simpler vector 
#dealing with negative values and normalizing absorbance spectra

```{r}
library (pavo) 
set.seed(12345) 
spec <- read.csv("Concentration.csv")
#spec <- t(spec) 
#write.csv(spec,"spectra.csv")
```

### Now we interpolate the data in 1-nm bins and ### convert the data to an rspec object

```{r}
spec <- as.rspec(spec)
```


```{r}
is.rspec(spec)

# Plot raw spectra
par(mfrow=c(1,1))
plot(spec)
```


###### We need to get rid of the 
###### low SNR areas of spectra

```{r}
#Plot spectra with low SNR areas removed
#postscript("raw_specra.eps")
plot(spec, select = c(1,12,23), ylim = c(0, 1100))
```

```{r}
#abline(h = 0, lty = 3)
#dev.off()
#Truncate data to desired range (1002 and 2350 nm)
spec_truncated <- as.rspec(spec, lim = c(500, 1600))
```

```{r}
#Plot the data to see how it looks
plot(spec_truncated, select = 20, ylim = c(0, 80))
```

```{r}
# create a vector with samples identity names
spp <- gsub('\\.[0-9].*$', '', names(spec_truncated))[-1]
table(spp)
```


## we can now convert the data to absorbance

```{r}
# we are going to use the spp vector we created to tell the
# aggspec() function how to average the spectra in mspecs :
sppspec <- aggspec(spec_truncated, by = spp, FUN = mean)
round(sppspec[1:5, ], 2)
```

```{r}
#Normalizing and Smoothing Spectra
plotsmooth(sppspec, minsmooth = 0.05,
maxsmooth = 0.5, curves = 4, ask = FALSE)
```

```{r}
spec.sm <- procspec(sppspec, opt = "smooth", span = 0.05)
```



```{r}
## processing options applied:
## smoothing spectra with a span of 0.2
plot(sppspec[,2] ~ sppspec[, 1],
type = "l", lwd = 10, col = "grey",
xlab = "Wavelength (nm)", ylab = "Reflectance (%)"
)
lines(spec.sm[,2] ~ sppspec[, 1], col = "red", lwd = 2)
```

```{r}
# Run some different normalisations
specs.max <- procspec(sppspec, opt = "max")
```

```{r}
## processing options applied:
## Scaling spectra to a maximum value of 1
specs.min <- procspec(sppspec, opt = "min")
```

```{r}
 ## processing options applied:
## Scaling spectra to a minimum value of zero
specs.str <- procspec(sppspec, opt = c("min", "max")) # multiple options
```

```{r}
## processing options applied:
## Scaling spectra to a minimum value of zero
## Scaling spectra to a maximum value of 1
# Plot results
par(mfrow = c(1, 3), mar = c(2, 2, 2, 2), oma = c(3, 3, 0, 0))
plot(specs.min[,2] ~ c(500:1600), xlab = "", ylab = "", type = "l")
abline(h = 0, lty = 2)
plot(specs.max[,2] ~ c(500:1600), ylim = c(0, 1), xlab = "", ylab = "", type = "l")
abline(h = c(0, 1), lty = 2)
plot(specs.str[,2 ] ~ c(500:1600), type = "l", xlab = "", ylab = "")
abline(h = c(0, 1), lty = 2)
mtext("Wavelength (nm)", side = 1, outer = TRUE, line = 1)
mtext("Normalised reflectance (%)", side = 2, outer = TRUE, line = 1)
```

```{r}
par(mfrow = c(1, 2), mar = c(4, 4, 2, 2), oma = c(2, 0, 0, 0))
# Plot using median and standard deviation, default colours
aggplot(spec_truncated, spp,
FUN.center = median,
ylim = c(0, 100),
alpha = 0.3,
legend=F)
# Plot using mean and standard error, in greyscale
aggplot(spec_truncated, spp,
ylim = c(0, 100),
FUN.error = function(x) sd(x) / sqrt(length(x)),
lcol = 1, shadecol = "grey", alpha = 0.7)
```



```{r}
par(xpd = FALSE)
#extract first component of filenames containing species names
spp <- do.call(rbind, strsplit(names(spec_truncated), "\\."))[, 1]

class(spec_truncated)
```

```{r}
# Save the truncated data to a csv file
# Define the file path where you want to save the CSV file
file_path <- "D:/Downloads/spec_truncated.csv"

# Write the data to a CSV file
write.csv(spec_truncated, file = file_path, row.names = FALSE)

# Transpose the data frame
spec_truncated_transposed <- t(spec_truncated)

# Convert transposed data into a data frame
spec_truncated_transposed <- as.data.frame(spec_truncated_transposed, col.names = TRUE)

# Save the transposed data to a CSV file
file_path <- "D:/Downloads/spec_truncated_transposed.csv"
write.csv(spec_truncated_transposed, file = file_path, row.names = FALSE)


```

```{r}
# Load truncated data, Before loading the data, manually delete the first row which
# cointains v1,v2,v3...e.t.c.. which is created when we convert a matrix to a dataframe
spectra <- read.csv("spec_truncated1.csv",
sep = ",",
dec = ".",
header = TRUE)
```

```{r}
#check the data
spectra[1:10,1:5]
```

```{r}
# Create a data frame called mydata with two columns:
# - 'label' column containing wavelength values from spectra$wl
# - 'DRS' column containing reflectance values from spectra[2:ncol(spectra)]
mydata <- data.frame(label=I(spectra$wl),
DRS = I(spectra[2:ncol(spectra)]))
# Retrieve wavelength numbers from column names of DRS column in mydata
wavelengths<-substring(colnames(mydata$DRS),2,6) # using substring() function to extract the 2nd to 4th characters from column names
wavelengths<-as.numeric(wavelengths) # convert extracted characters into numeric values
head(wavelengths) # display the wavelength numbers
```


```{r}
#Define a custom function for ploting the data to save us the headache

mercy_plot <- function(mydata, wavelengths, xlim, ylim, main, ylab, x, y) {
# Find unique labels using gsub
unique_labels <- unique(gsub("[^A-Za-z]+", "", mydata$label))
num_labels <- length(unique_labels)
# Create color palette
color_palette <- rainbow(num_labels)
names(color_palette) <- unique_labels
# Initialize the plot
plot(NULL, xlim = xlim, ylim = ylim, xlab = "Wavelength (nm)", ylab = ylab, main = main)
# Plot spectra
for (label in unique_labels) {
subset_data <- mydata[gsub("[^A-Za-z]+", "", mydata$label) == label, ]
subset_wavelengths <- wavelengths
subset_drs <- subset_data$DRS
subset_color <- color_palette[label]
matlines(subset_wavelengths, t(subset_drs), col = subset_color, lty = 1, lwd = 2)
}
# Add minor tick marks
minor.tick(nx = 2, ny = 2, tick.ratio = 0.75)
# Create a legend for the groups
#legend_labels <- unique_labels
#legend_colors <- color_palette[unique_labels]
#legend(x, y, legend = legend_labels, fill = legend_colors, title = "Samples", bty = "n")
}
#Set some default parameters
xlim<-c(500,1600)
ylim<-c(-10,12000)
main<- ""
ylab<- ""
```




```{r}
#plot the raw data
mercy_plot(mydata, wavelengths,xlim,ylim =c(-100,13000),x=1600,y=1600,
main = "Raw Raman spectra",ylab = "Reflectance (%)")
```

```{r}
# Absorb is a function that takes in a matrix of spectra as input
# and returns a matrix of absorbances calculated using the equation
# log10(1/R), where R is the reflectance.
Absorb <- function(spectra) {
        # Convert spectra to a matrix
        spectra <- as.matrix(spectra)
        # Calculate absorbances using log10(1/R)
        spect_Absorb <- log10(1/spectra)
        # Return the matrix of absorbances
        return(spect_Absorb)
}
# Perform conversion
# Apply the Absorb function to the DRS column of the mydata data frame
# and store the result in the newspectra variable.
newspectra <- Absorb(mydata$DRS)
# Check for NaN values in the newspectra matrix using the table function.
# If there are any NaN values, they will be printed in the output.
table(is.nan(newspectra))
```

```{r}
# Creates a new data frame called mydataAbsorb, which includes the 'label' column from mydata
# and a new column 'DRS' which contains the new spectra from newspectra.
mydataAbsorb1 <- data.frame(label=I(mydata$label), DRS = I(newspectra))
# Plot the new spectra using the function 'mercy_plot'
# Add minor tick mar
mercy_plot(mydataAbsorb1, wavelengths, xlim, ylim = c(-2,0.15),x=1600,y=0,
main = "Absorbance from Reflectance",ylab = "Absorbance (a.u)")
# Save the data frame to a CSV file
#write.csv(mydataAbsorb1, "mydataAbsorb1.csv")
```

```{r}
# Convert mydataAbsorb to a data frame with the rows and columns transposed.
mydataAbsorb <- as.data.frame(t(mydataAbsorb1))
 #Write the data in mydataAbsorb to a CSV file called "Absorb_trans_data.csv".
#write.csv(mydataAbsorb,"Absorb_trans_data.csv")
# AFTER SAVING THE DATASET, OPEN IT AND MODIFY IT MANUAL TO REMOVE ANY DISCREPANCES INTRODUCED eg the DRS.X in the wavelengths (first column)
# Remove the object 'newspectra' from memory.
rm(newspectra)
```

```{r}
# Read the absorbance data from a csv file and convert it to an rspec object
spec <- read.csv("Concentration1.csv")
spec <- as.rspec(spec)
```



```{r}
# Check if the object is of class 'rspec'
is.rspec(spec)

```
```{r}
# Set the plotting layout to a single row and column
par(mfrow=c(1,1))
# Plot the absorbance spectra
plot(spec)
```
```{r}
# Create a copy of the spectra for testing purposes
testspecs <- spec
# Reset the plotting layout to the default
par(mfrow=c(1,1))
```


```{r}
###################################################################
# Now we can Apply two different processing options to the data
testspecs.fix1 <- procspec(testspecs, fixneg = "addmin")
```

```{r}
testspecs.fix2 <- procspec(testspecs, fixneg = "zero")
```

```{r}
# Plot it
par(mfrow=c(1,1))
par(mar = c(2, 2, 2, 2), oma = c(3, 3, 0, 0))
layout(cbind(c(1, 1), c(2, 3)), widths = c(2, 1, 1))
plot(testspecs, select = 2, ylim = c(-1.9, -0.5))
abline(h = 0, lty = 3)
plot(testspecs.fix1, select = 2, ylim = c(0, 1))
abline(h = 0, lty = 3)
plot(testspecs.fix2, select = 2, ylim = c(0, 0.001))
abline(h = 0, lty = 3)
mtext("Wavelength (nm)", side = 1, outer = TRUE, line = 1)
mtext("Log10(1/R)", side = 2, outer = TRUE, line = 1)
```

```{r}
par(mfrow=c(1,1))
```

Normalizing and Smoothing Spectra

```{r}
# use the plotsmooth() function to determine a suitable smoothing parameter (span). This function
# allows you to set a minimum and maximum smoothing parameter to try and plots the resulting curves against
# the unsmoothed (raw) data in a convenient multipanel figure.-
sppspec <- testspecs.fix1
plotsmooth(sppspec, minsmooth = 0.01, maxsmooth = 0.09,
curves = 5,specnum = "6",ask = FALSE)
```

```{r}
##From the resulting plot, we can see that span = 0.07 is the minimum amount of smoothing to remove spectral noise
# while preserving the original spectral shape. Based on this value, we will now use the opt argument in procspec()
# to smooth data for further plotting and analysis.
par(mfrow=c(1,1))
spec.sm <- procspec(sppspec, opt = "smooth", span = 0.09)
```

```{r}
plot(sppspec[, 2] ~ sppspec[, 1],
type = "l",
lwd = 10,
col = "grey",xlab = "Wavelength (nm)",ylab = "Log10(1/R)",
main="Smoothing with 0.07 pan")
mtext("Wavelength (nm)", side = 1, outer = TRUE, line = 1)
mtext("Log10(1/R)", side = 2, outer = TRUE, line = 1)
par(mfrow=c(1,1))
lines(spec.sm[, 2] ~ sppspec[, 1], col = "red",lwd = 2)
```

```{r}

##We can also try different normalisations. Options include subtracting the minimum Log (1/R) of a spectrum at
# all wavelengths (effectively making the minimum Log (1/R) equal to zero, opt = "min", left panel, below) and
# making the Log (1/R) at all wavelength proportional to the maximum Log (1/R) (i.e. setting maximum Log (1/R)
# to 1; opt = "max", centre panel, below). Note that the user can specify multiple processing options that will be
# applied sequentially to the spectral data by procspec() (right panel, below).
# Run normalization with maximum value of 1
specs.max <- procspec(spec.sm, opt = "max")


```
```{r}
specs.min <- procspec(spec.sm, opt = "min")
```
```{r}
specs.str <- procspec(spec.sm, opt = c("min", "max")) # multiple options
```

```{r}
# Plot results


par(mfrow = c(1, 3), mar = c(2, 2, 2, 2), oma = c(3, 3, 0, 0))
plot(specs.min[, 2] ~ c(500:1600), xlab = "", ylab = "", type = "l")
abline(h = 0, lty = 2)
plot(specs.max[, 2] ~ c(500:1600), ylim = c(0, 1),
xlab = "", ylab = "", type = "l")
abline(h = c(0, 1), lty = 2)
plot(specs.str[, 2] ~ c(500:1600), type = "l", xlab = "", ylab = "")
abline(h = c(0, 1), lty = 2)
mtext("Wavelength (nm)", side = 1, outer = TRUE, line = 1)
mtext("Normalised Log (1/R)", side = 2, outer = TRUE, line = 1)
```

```{r}
par(mfrow=c(1,1))


 write.csv(specs.str,"cleaned_drs_absorbance_data4.csv")
 specs.str1<-t(specs.str)
write.csv(specs.str1,"cleaned_trans_drs_absorbance_data4.csv")
```

```{r}
spectra<- read.csv("cleaned_trans_drs_absorbance_data4.csv",
sep=",",dec=".",header=TRUE)
spectra[1:10,1:5]
```

```{r}
mydata <- data.frame(label=I(spectra$wl),
                     #samples=I(spectra$samples),
                     DRS = I(spectra[2:ncol(spectra)]))


#Retrieve wavelength numbers from colomn names: 
wavelengths<-substring(colnames(mydata$DRS),2,7)
wavelengths<-as.numeric(wavelengths)

#Sort the data by decreasing SN values: 
mydata<-mydata[order(mydata$label, decreasing = T),]

#plot the raw data 
mercy_plot(mydata, wavelengths, xlim=c(500,1600), ylim =c(0,1),x=900,y=1,
            main = "DRS Absorbance Spectra",ylab = "Log (1/R)  a.u.") 
```




```{r}
library(signal) 
library(pls)

# Set output directory
output_directory <- "D:/Downloads/"

# Function to normalize spectra
normalize_spectra <- function(spectra) {
  spectra <- as.matrix(spectra)
  min_val <- apply(spectra, 1, min)
  max_val <- apply(spectra, 1, max)
  normalized_spectra <- (spectra - min_val) / (max_val - min_val)
  return(normalized_spectra)
}

# Apply Savitzky-Golay smoothing for first and second derivatives
apply_sgolay <- function(spectra, p, n, m) {
  apply(spectra, 1, FUN = sgolayfilt, p = p, n = n, m = m, ts = 1)
}

# SNV function
SNV <- function(spectra) {
  spectra <- as.matrix(spectra)
  spectrat <- t(spectra)
  spectrat_snv <- scale(spectrat, center = TRUE, scale = TRUE)
  spectra_snv <- t(spectrat_snv)
  return(spectra_snv)
}


# Apply Savitzky-Golay smoothing
mydataSmoothSG <- apply_sgolay(mydata$DRS, p = 2, n = 5, m = 0)
mydataFirstDerivative <- apply_sgolay(mydata$DRS, p = 2, n = 5, m = 1)
mydataSecondDerivative <- apply_sgolay(mydata$DRS, p = 2, n = 5, m = 2)

# Convert to data frame
mydataSmoothSG <- data.frame(label = I(mydata$label), DRS = I(t(mydataSmoothSG)))
mydataFirstDerivative <- data.frame(label = I(mydata$label), DRS = I(t(mydataFirstDerivative)))
mydataSecondDerivative <- data.frame(label = I(mydata$label), DRS = I(t(mydataSecondDerivative)))

# Apply SNV and MSC corrections

## Savitzky-Golay Smoothed Spectra (0th Derivative)
# SNV on Savitzky-Golay smoothed spectra
snv_spectra_sg <- SNV(mydataSmoothSG$DRS)
mydataSmoothSG_SNV <- data.frame(label = I(mydataSmoothSG$label), DRS = I(snv_spectra_sg))


# Normalize SNV and MSC corrected Savitzky-Golay smoothed spectra
normalized_snv_sg <- normalize_spectra(mydataSmoothSG_SNV$DRS)
mydataSmoothSG_SNV_normalized <- data.frame(label = I(mydataSmoothSG_SNV$label), DRS = I(normalized_snv_sg))

#normalized_msc_sg <- normalize_spectra(mydataSmoothSG_MSC$DRS)
#mydataSmoothSG_MSC_normalized <- data.frame(label = I(mydataSmoothSG_MSC$label), DRS = I(normalized_msc_sg))

## First Derivative Spectra
# SNV on first derivative spectra
snv_spectra_first_derivative <- SNV(mydataFirstDerivative$DRS)
mydataFirstDerivative_SNV <- data.frame(label = I(mydataFirstDerivative$label), DRS = I(snv_spectra_first_derivative))

# MSC on first derivative spectra
#msc_spectra_first_derivative <- msc(mydataFirstDerivative$DRS)
#mydataFirstDerivative_MSC <- data.frame(label = I(mydataFirstDerivative$label), DRS = I(msc_spectra_first_derivative))

# Normalize SNV and MSC corrected first derivative spectra
normalized_snv_first_derivative <- normalize_spectra(mydataFirstDerivative_SNV$DRS)
mydataFirstDerivative_SNV_normalized <- data.frame(label = I(mydataFirstDerivative_SNV$label), DRS = I(normalized_snv_first_derivative))

#normalized_msc_first_derivative <- normalize_spectra(mydataFirstDerivative_MSC$DRS)
#mydataFirstDerivative_MSC_normalized <- data.frame(label = I(mydataFirstDerivative_MSC$label), DRS = #I(normalized_msc_first_derivative))

## Second Derivative Spectra
# SNV on second derivative spectra
snv_spectra_second_derivative <- SNV(mydataSecondDerivative$DRS)
mydataSecondDerivative_SNV <- data.frame(label = I(mydataSecondDerivative$label), DRS = I(snv_spectra_second_derivative))



# Normalize SNV and MSC corrected second derivative spectra
normalized_snv_second_derivative <- normalize_spectra(mydataSecondDerivative_SNV$DRS)
mydataSecondDerivative_SNV_normalized <- data.frame(label = I(mydataSecondDerivative_SNV$label), DRS = I(normalized_snv_second_derivative))


# Save files
write.csv(mydataSmoothSG, file.path(output_directory, "savitzky_golay_spectra.csv"), row.names = FALSE)
write.csv(mydataSmoothSG_SNV, file.path(output_directory, "savitzky_golay_snv_spectra.csv"), row.names = FALSE)
#write.csv(mydataSmoothSG_MSC, file.path(output_directory, "savitzky_golay_msc_spectra.csv"), row.names = FALSE)
write.csv(mydataSmoothSG_SNV_normalized, file.path(output_directory, "normalized_savitzky_golay_snv_spectra.csv"), row.names = FALSE)
#write.csv(mydataSmoothSG_MSC_normalized, file.path(output_directory, "normalized_savitzky_golay_msc_spectra.csv"), row.names = FALSE)

#write.csv(mydataFirstDerivative, file.path(output_directory, "first_derivative_spectra.csv"), row.names = FALSE)
#write.csv(mydataFirstDerivative_SNV, file.path(output_directory, "first_derivative_snv_spectra.csv"), row.names = FALSE)
#write.csv(mydataFirstDerivative_MSC, file.path(output_directory, "first_derivative_msc_spectra.csv"), row.names = FALSE)
write.csv(mydataFirstDerivative_SNV_normalized, file.path(output_directory, "normalized_first_derivative_snv_spectra.csv"), row.names = FALSE)
#write.csv(mydataFirstDerivative_MSC_normalized, file.path(output_directory, "normalized_first_derivative_msc_spectra.csv"), row.names = FALSE)

#write.csv(mydataSecondDerivative, file.path(output_directory, "second_derivative_spectra.csv"), row.names = FALSE)
#write.csv(mydataSecondDerivative_SNV, file.path(output_directory, "second_derivative_snv_spectra.csv"), row.names = FALSE)
#write.csv(mydataSecondDerivative_MSC, file.path(output_directory, "second_derivative_msc_spectra.csv"), row.names = FALSE)
write.csv(mydataSecondDerivative_SNV_normalized, file.path(output_directory, "normalized_second_derivative_snv_spectra.csv"), row.names = FALSE)
#write.csv(mydataSecondDerivative_MSC_normalized, file.path(output_directory, "normalized_second_derivative_msc_spectra.csv"), row.names = FALSE)


```



```{r}
# Define a custom function for plotting and saving spectra
plot_spectra <- function(mydata, wavelengths, title, ylim_min, ylim_max, ylab, filename) {
  png(filename, width = 800, height = 600)
  mercy_plot(mydata, wavelengths, xlim = c(500, 1600), ylim = c(ylim_min, ylim_max), main = title, ylab = ylab, x = 1500, y = 1)
  dev.off()
}


plot_spectra(mydataSmoothSG_SNV_normalized, wavelengths, "Normalized Savitzky-Golay Smoothed Spectra with SNV", 0, 1, "Normalized Log (1/R) a.u.", file.path(output_directory, "normalized_savitzky_golay_snv_spectra.png"))


plot_spectra(mydataFirstDerivative_SNV_normalized, wavelengths, "Normalized First Derivative Spectra with SNV", 0, 1, "Normalized Log (1/R) a.u.", file.path(output_directory, "normalized_first_derivative_snv_spectra.png"))


plot_spectra(mydataSecondDerivative_SNV_normalized, wavelengths, "Normalized Second Derivative Spectra with SNV", 0, 1, "Normalized Log (1/R) a.u.", file.path(output_directory, "normalized_second_derivative_snv_spectra.png"))


```








##########################################################################################################

Create smoothing function:

```{r}
SmoothFast<-function(Spectra,windowsize){                         
     
     #Create smoothing matrix: 
     Mat<-matrix(0,length((windowsize+1):(ncol(Spectra)-windowsize)),2*windowsize+1)
     for(j in 1:nrow(Mat)){Mat[j,]<-seq(j,j+2*windowsize,1)}
     
     #Smoothing spectra using matrix operations:
     newspectra<-matrix(0,nrow(Spectra),
                        length((windowsize+1):(ncol(Spectra)-windowsize)))
     for(i in 1:nrow(Mat)){newspectra[,i]<-apply(Spectra[,Mat[i,]],1,mean)}
     
     #Add front and end tails (not smoothed):
     fronttail<-newspectra[,1]
     endtail<-newspectra[,ncol(newspectra)]
     for(k in 1:(windowsize-1)){fronttail<-data.frame(fronttail,newspectra[,1])
     endtail<-data.frame(endtail,newspectra[,ncol(newspectra)])}
     newspectra<-data.frame(fronttail,newspectra,endtail)
     
     return(newspectra)}

#Apply smoothing function:
newspectra<-SmoothFast(mydata$DRS,windowsize=3)

mydataSmooth <- data.frame(label=I(mydata$label),
                           DRS = I(newspectra))
rm(newspectra)

#Plot smoothed spectra:
mercy_plot(mydataSmooth, wavelengths,xlim=c(1005,2500), ylim =c(0,1.2),x=2300,y=1,
            main = "Moving Average",ylab = "Log (1/R)  a.u")
```




```{r}
library (signal) 
#Apply Savitzky-Golay smoothing to all spectra:
mydataSmooth <-apply (mydata $ DRS,1, FUN=sgolayfilt, p = 2, n = 3, m = 1, ts = 1) 
#Create new data frame: 
mydataSmoothSG <-data.frame (label= I (mydata $ label), 
DRS = I ( t (mydataSmooth))) 
rm (newspectra)
#Plot spectra:
mercy_plot(mydataSmoothSG, wavelengths, xlim = c(1005, 2500), ylim = c(-.005,.01 ), x = 2300, y = 1,
            main = "Savitzky-Golay", ylab = "Log (1/R) a.u.")
```

# Perform MSC correction:

```{r}
# Load the necessary library
library(pls)

# Assuming mydataSmoothSG and wavelengths are already defined in your workspace
# Ensure 'mydataSmoothSG$DRS' is a numeric matrix
mydataSmoothSG_matrix <- as.matrix(mydataSmoothSG$DRS)

# Apply MSC to the smoothed spectra
msc_spectra <- msc(mydataSmoothSG_matrix)

# Create a new data frame with MSC-corrected spectra
mydataMSC <- data.frame(label = I(mydataSmoothSG$label),
                        DRS = I(msc_spectra))
rm(msc_spectra)
#Plot new spectra:
mercy_plot(mydataMSC, wavelengths, xlim=c(1005,2500), ylim =c(-0.005,0.01),x=2300,y=2,
            main = "Multiplicative Scatter Correction (MSC)",ylab = "Log (1/R)  a.u")
```

```{r}
# Function to normalize spectra
normalize_spectra <- function(spectra) {
  spectra <- as.matrix(spectra)
  min_val <- apply(spectra, 1, min)
  max_val <- apply(spectra, 1, max)
  normalized_spectra <- (spectra - min_val) / (max_val - min_val)
  return(normalized_spectra)
}

# Apply normalization to the MSC-corrected spectra
normalized_spectra <- normalize_spectra(mydataMSC$DRS)

# Create a new data frame with normalized MSC-corrected spectra
mydataMSC_normalized <- data.frame(label = I(mydataMSC$label),
                                   DRS = I(normalized_spectra))

# Plot the normalized MSC-corrected spectra
mercy_plot(mydataMSC_normalized, wavelengths, xlim = c(1005, 2500), ylim = c(0, 1), x = 2300, y = 1,
            main = "Normalized MSC", ylab = "Normalized Log (1/R) a.u")

```
```{r}
# Define the directory and file name
output_directory <- "D:/Downloads"
output_file <- "normalized_MSC_spectra.csv"

# Combine the directory and file name
output_path <- file.path(output_directory, output_file)

# Save the mydataMSC_normalized data frame as a CSV file
write.csv(mydataMSC_normalized, output_path, row.names = FALSE)

# Plot the normalized MSC-corrected spectra
mercy_plot(mydataMSC_normalized, wavelengths, xlim = c(500, 1000), ylim = c(0, 1), x = 2300, y = 1,
           main = "Normalized MSC", ylab = "Normalized Log (1/R) a.u")

# Print message to confirm the file has been saved
cat("The file has been saved to", output_path, "\n")

```
#####################################################################################

```{r}
### pca using chemospec 
#rm ( list = ls ()) 
```

```{r}
#MSCdata <- as.data.frame(t(t(mydataMSC_normalized)))
#MSCdata <- t(mydataMSC) 
#str(MSCdata) 
#write.csv(MSCdata,"msc_data7.csv")
```


<!-- ## Loading the packages we will use -->

```{r packages, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(ChemoSpecUtils)
library(ChemoSpec)
library(chemometrics)
library(knitr)
library(R.utils)
library(utils)
library(kableExtra) 
library(tinytex)
```



```{r}
#setwd ("pca ␣ 2021")
```

<!-- ## Reading a matrix data file stored in the working directory -->

<!-- Ensure first that you have set the working directory where your data is located, idealy on your desktop in a folder for easier access. -->


```{r}
spec <- matrix2SpectraObject(gr.crit = c("AZ","AB","AA"),
gr.cols = c("blue", "green","red"),
freq.unit = "Wavelength (nm)",
int.unit = "intensity",
descrip = "Study",
in.file = "Normalized4.csv",
out.file = "horm",
chk = TRUE,
sep = ",",
dec = ".")

```



<!-- As it can be seen clearly, the data has 567 spectra and 3 groups from the group criteria, "CS","BF" and "M72" -->

## Summary of the data
<!-- We can look at our data summary using the "sumSpectra" function available in chemospec -->
```{r echo=FALSE}
sumSpectra(spec)
```

##  Plotting all the spectra

<!-- we can visualize the spectra using the "plotSpectra" function and colour them according to the colour criteria that we  had specified. -->
```{r echo=FALSE}
plotSpectra(spec,
            main = "MSC Spectra",
            which = c(1:22),
            yrange = c(1,4500.),
            xlim =c(10,2000),
            offset = 0.0001,
            showGrid = FALSE,
            lab.pos = 2000,
            leg.loc = "topright")
```

```{r}
# Feature selections
# VIS spectra# 
VISspec <- spec
```

```{r}
# Plotting the spectra 
plotSpectra(VISspec, 
main = "VIS ␣ MSC ␣ Spectra",
which = c (1:22),
yrange = c (0,1.2), 
offset = 0, 
lab.pos = 2350, 
showGrid = F, 
leg.loc = "topright")
```

```{r}
# NIR spectra #
NIRspec <- removeFreq(spec, rem.freq = spec$freq > 1580| spec$freq < 1450)
# Plotting the spectra 
plotSpectra(NIRspec, 
main = "NIR ␣ MSC ␣ Spectra",
which = c (1:22),
yrange = c (10,2000), 
offset = 0,
lab.pos = 10,
showGrid = F, 
leg.loc = "topleft")
```

```{r}
# NORMALIZING THE SPECTRA # 
#VISspec <- normSpectra(VISspec) 
NIRspec <- normSpectra(NIRspec)
```

```{r}
# PCA analysis of the VIS spectras #
VISpca <-c_pcaSpectra(VISspec, 
choice = "autoscale", 
cent = T)
```

```{r}
plotScores(VISspec, VISpca,
main ="VIS ␣ Spectra",
pcs = c (1,2), 
ellipse = "none", 
tol = "none", 
leg.loc ="right") 
 #tol = 0.05) 
#abline (v=0,h=0) 
cv_pcaSpectra(VISspec, 
pcs =5)
```

```{r}
plotLoadings(VISspec, 
VISpca, 
main = "VIS ␣ Spectra",
loads = c (1, 2), 
ref = 91,
tol = "none")
```

```{r}
plot2Loadings(VISspec, 
VISpca, 
main = "VIS ␣ Spectra",
loads = c (1, 2), 
ref = 91, 
tol = "none")
```

```{r}
sPlotSpectra( VISspec,
VISpca,
pc = 1, 
tol = 0.001, 
main = "VIS ␣ Spectra")
```

```{r}
# To check pca outliers 
diagnostics <- pcaDiag(VISspec,
VISpca, 
pcs = 3, 
quantile = 0.916, 
plot = "SD")
```

```{r}
# Scree plot 
plot (VISpca, type = "l") 
plotScree(VISpca, style = "alt", 
main = "VIS ␣ Spectra")
```

```{r}
# PCA analysis of the NIR spectras ## 
NIRpca <-c_pcaSpectra(NIRspec, 
choice = "autoscale") 
#cent = T)
```

```{r}
plotScores(NIRspec, 
NIRpca,
main ="NIR ␣ Spectra",
pcs = c (1,2),
ellipse = "none", 
tol = "none", 
leg.loc ="topright") 
# tol = 0.05) 
#abline (v=0,h=0)
```

```{r}
cv_pcaSpectra(NIRspec, 
pcs = 10)
```

```{r}
plotLoadings(NIRspec, 
NIRpca, main = "NIR ␣ Spectra", 
loads = c (1, 2), 
ref = 91, 
tol = "none")
```

```{r}
plot2Loadings(NIRspec, 
NIRpca, 
main = "NIR ␣ Spectra",
loads = c (1, 2), 
ref = 91,
tol = "none")
```

```{r}
sPlotSpectra( NIRspec,
NIRpca,
pc = 1,
tol = 0.001,
main = "NIR ␣ Spectra")
```

```{r}
# To check pca outliers 
diagnostics <- pcaDiag(NIRspec,
NIRpca, 
pcs = 1, 
quantile = 0.999, 
plot = "SD", 
use.sym = F)
```


```{r}
diagnostics <- pcaDiag(NIRspec, 
NIRpca, 
pcs = 1, 
quantile = 0.999, 
plot = "OD", 
use.sym = F)
```

find outliers 

```{r}
x <- as.data.frame (diagnostics[["SDist"]]) 
y <-as.data.frame ( as.factor (spec[["names"]]))
```

```{r}
# Inspect diagnostics and spec
#str(diagnostics)
#str(spec)

# Check if the specific elements exist and have the expected length
print(length(diagnostics[["SDist"]]))
print(length(spec[["names"]]))

```



```{r}
#library (dplyr) 
#s <- bind_cols(x,y)
```

#write.csv(s," / home / mercy / Desktop / pca journal data analysis / s.→ csv")

```{r}
# Scree plot 
plot (NIRpca, type = "l")
```

```{r}
plotScree(NIRpca, style = "alt",
main = "VIS ␣ Spectra")
```

```{r}
#### Extract the first 10 PC scores for modeling
PCA_scores1 <- as.data.frame(NIRpca[["x"]]) 
PCA_scores <- as.data.frame(PCA_scores1[,1:3]) 
data_labels <- as.data.frame(spec[["groups"]]) 

```

```{r}
 library(dplyr)
PCA_data <- bind_cols(groups=data_labels,PCA_scores)
write.csv(PCA_data,"Machine1.csv")
```
```{r}
# Load libraries
library(neuralnet)
library(caret)

# Read data
mydata <- read.csv('pcadata203.csv', sep = ",", header = TRUE)
## normalisaion of data
normalize <- function(x) {
  x <- as.numeric(x)
  return((x - min(x)) / (max(x) - min(x)))
}
Data <- as.data.frame(apply(mydata, 2, normalize))


 #Data partitioning
indexs <- sample(1:nrow(mydata), round(0.50 * nrow(mydata)))
train_data <- mydata[indexs, ]
test_data <- mydata[-indexs, ]

# Neural network model
model <- neuralnet(groups ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9, 
                   data = train_data, 
                   hidden = c(10,5), 
                   act.fct = "logistic", 
                   threshold = 0.01, 
                   algorithm = "rprop+", 
                   err.fct = "sse", 
                   linear.output = TRUE,
                   stepmax = 1e6)  # Increasing stepmax to a very large number

# Plot model
plot(model)

# Predictions on training data
predcal_data <- compute(model, train_data[, c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6", "PC7", "PC8", "PC9")])
pred_trainNN <- predcal_data$net.result
actual_train <- data.frame(pred = predcal_data$net.result, actual = train_data$groups)

# Write predictions to CSV
write.csv(actual_train, "DM train44.csv")

# Error metrics on training data
RMSEcal_model <- sqrt(sum((train_data$groups - pred_trainNN)^2) / nrow(train_data))
Rsquaredcal_model <- 1 - sum((train_data$groups - pred_trainNN)^2) / sum((train_data$groups - mean(train_data$groups))^2)
MAEcal_model <- sqrt(sum((train_data$groups - pred_trainNN)^2) / nrow(train_data))

# Predictions on test data
pred_data <- compute(model, test_data[, c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6", "PC7", "PC8", "PC9")])
pred_testNN <- pred_data$net.result
actual_pred <- data.frame(pre = pred_data$net.result, actual = test_data$groups)

# Write predictions to CSV
write.csv(actual_pred, "DM test44.csv")

# Plot actual vs predicted
plot(actual_pred, main = "Predicted dry matter percentage  vs Actual dry matter percentage", col = 'blue', xlab = "Actual concentration", ylab = "Predicted dry matter percentage", pch = 16, type = "p")
#abline(0, 1, col = "black")

# Error metrics on test data
RMSEpred_model <- sqrt(sum((test_data$groups - pred_testNN)^2) / nrow(test_data))
Rsquaredpred_model <- 1 - sum((test_data$groups - pred_testNN)^2) / sum((test_data$groups - mean(test_data$groups))^2)
MAEpred_model <- sqrt(sum((test_data$groups - pred_testNN)^2) / nrow(test_data))
# Save model
save(model, file = "model")

# Load model
load(file = "model")

# Read input data for prediction
inputdata <- read.csv("pcadata81.CSV", sep = ',', header = TRUE)

# Normalize input_data based on the same normalization used during training if necessary
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}
normalisedinData <- as.data.frame(lapply(inputdata, normalize))

# Ensure predictor_data has the same columns used during model training
predictor_data <- normalisedinData[, c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6", "PC7", "PC8", "PC9", "PC10")]

# Predict using the model
val_data_model_group2_est <- compute(model, predictor_data)

# Extract predicted values
predicted_values <- val_data_model_group2_est$net.result

# Denormalize the predicted values based on the groups column of inputdata
denormalizedval_model_data_group2_est <- predicted_values * (max(inputdata$groups) - min(inputdata$groups)) + min(inputdata$groups)

# Combine the denormalized predicted values with actual groups from inputdata
result <- data.frame(actual = inputdata$groups, predicted = denormalizedval_model_data_group2_est)

# Write the result to a CSV file
write.csv(result, "Group2_est_predconc1.csv", row.names = FALSE)
# Calculate RMSE and R-squared on validation set
RMSE_val <- sqrt(mean((inputdata$groups - denormalizedval_model_data_group2_est)^2))
Rsquared_val <- 1 - sum((inputdata$groups - denormalizedval_model_data_group2_est)^2) / sum((inputdata$groups - mean(inputdata$groups))^2)

# Print validation metrics
print(paste("RMSE on validation set:", RMSE_val))
print(paste("R-squared on validation set:", Rsquared_val))
```

#####Plotiing linear regression line###
```{r}
# Load necessary libraries
library(ggplot2)

# Read the data
mydata <- read.csv('csv', sep = ",", header = TRUE)

# Fit a linear model
model <- lm(pred ~ actual, data = mydata)

# Print the model summary
summary(model)

# Extract R-squared value and coefficients
r_squared <- summary(model)$r.squared
intercept <- coef(model)[1]
slope <- coef(model)[2]

# Plot actual vs. predicted values with a regression line and conf
ggplot(mydata, aes(x = actual, y = pred)) +
  geom_point(color = "darkblue", alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "black", fill = "lightblue", size = 1) +
  labs(x = "Actual percentage", y = "Predicted percentage", 
     title = "Actual vs. Predicted dry matter") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.background = element_rect(color = "black", fill = NA, size = 1)) +
  annotate("text", x = min(mydata$actual), y = max(mydata$pre), 
        label = paste("R^2 =", round(r_squared, 3)), 
          hjust = 0, vjust = 1, size = 5, color = "black") +
  annotate("text", x = min(mydata$actual), y = max(mydata$pred) - (max(mydata$pred) - min(mydata$pred)) * 0.1, 
           label = paste("Intercept =", round(intercept, 3)), 
           hjust = 0, vjust = 1, size = 5, color = "black") +
  annotate("text", x = min(mydata$actual), y = max(mydata$pred) - (max(mydata$pred) - min(mydata$pred)) * 0.2, 
           label = paste("Slope =", round(slope, 3)), 
           hjust = 0, vjust = 1, size = 5, color = "black")
```
###SVM MODEL###

```{r}
#library(caret)
df <- read.csv("pcadata84.csv", header = TRUE)

str(df)
head(df)
intrain <- createDataPartition(y = df$Level, p = 0.50, list = FALSE)
training <- df[intrain,]
testing <- df[-intrain,]
dim(training)
dim(testing)
anyNA(df)
summary(df)

training[["Level"]] = factor(training[["Level"]])
trctrl <- trainControl(method = "repeatedcv", number = 30, repeats =10)
svm_Linear <- train(Level ~., data = training, method = "svmRadial",
                    trControl=trctrl,
                    preProcess = c("center", "scale"),
                   tunelength = 25)
                    
 # Print model details
svm_Linear

# Predict on the test set
test_pred <- predict(svm_Linear, newdata = testing)

# Fit a linear regression model on the test set predictions
model <- lm(test_pred ~ testing$Level)

# Extract R-squared value
r_squared <- summary(model)$r.squared
intercept <- coef(model)[1]
slope <- coef(model)[2]                   
# Print model details
svm_Linear

# Predict on the test set
test_pred <- predict(svm_Linear, newdata = testing)

# Fit a linear regression model on the test set predictions
model <- lm(testing$Level ~ test_pred)

# Extract R-squared value
r_squared <- summary(model)$r.squared
intercept <- coef(model)[1]
slope <- coef(model)[2]

# Plot actual vs. predicted values with a regression line
ggplot(data = testing, aes(x = Level, y = test_pred)) +
  geom_point(color = "darkblue", alpha = 0.6) +
  geom_abline(intercept = intercept, slope = slope, color = "blue", size = 1) +
  labs(x = "Actual concentration", y = "Predicted conentration", 
       title = "Actual concentration vs. Predicted concentration") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        panel.border = element_rect(color = "black", fill = NA, size = 1),
        plot.background = element_rect(color = "black", fill = NA, size = 1)) +
  annotate("text", x = min(testing$Level), y = max(test_pred), 
           label = paste("R^2 =", round(r_squared, 3)), 
           hjust = 0, vjust = 1, size = 5, color = "red") +
  annotate("text", x = min(testing$Level), y = max(test_pred) - (max(test_pred) - min(test_pred)) * 0.1, 
           label = paste("Intercept =", round(intercept, 3)), 
           hjust = 0, vjust = 1, size = 5, color = "red") +
  annotate("text", x = min(testing$Level), y = max(test_pred) - (max(test_pred) - min(test_pred)) * 0.2, 
           label = paste("Slope =", round(slope, 3)), 
           hjust = 0, vjust = 1, size = 5, color = "red")    
```

